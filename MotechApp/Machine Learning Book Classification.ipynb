{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_data_helper import motech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Hacking with Python The Ultimate Beginnerâ€™s Guide\n",
      "1          machine learning for the small and the many\n",
      "2    Applied Machine Learning, Feature encoding and...\n",
      "3    Hands-On Machine Learning with Scikit-Learn an...\n",
      "4    Hands-On Machine Learning with Scikit-Learn an...\n",
      "Name: BOOK, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = motech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY       0\n",
       "BOOK           0\n",
       "category_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY       object\n",
       "BOOK           object\n",
       "category_id     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Programming', 'Artificial Intelligence', 'Deep learning',\n",
       "       'Computer Science', 'deep learning', 'natural language processing',\n",
       "       'machine learning', 'Python OpenCV', 'Web development',\n",
       "       'Assembly Language', 'Data science', 'Machine learning'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique BOOKs\n",
    "df.CATEGORY.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Processing And Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(df.BOOK).toarray()\n",
    "labels = df.category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['BOOK'], df['CATEGORY'], random_state=0, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "x_train_occurences = count_vectorizer.fit_transform(x_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_tfidf = tfidf_transformer.fit_transform(x_train_occurences)\n",
    "model = LinearSVC().fit(x_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM is : 52.173913%\n",
      "Accuracy of SVM is : 52.631579%\n",
      "Accuracy of SVM is : 77.777778%\n",
      "Accuracy of SVM is : 64.705882%\n",
      "Accuracy of SVM is : 64.705882%\n",
      "Accuracy of SVM is : 80.000000%\n",
      "Accuracy of SVM is : 69.230769%\n",
      "Accuracy of SVM is : 75.000000%\n",
      "Accuracy of SVM is : 75.000000%\n",
      "Accuracy of SVM is : 83.333333%\n",
      "\n",
      "Mean Accuracy of SVM is  0.6945591370386094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "v = cross_val_score(model, x_tfidf, y_train, cv=10)\n",
    "for i in range(10):\n",
    "    print(\"Accuracy of SVM is : {0:2%}\".format(v[i,]))\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Mean Accuracy of SVM is \", v.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Prediction of books based on short phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning\n"
     ]
    }
   ],
   "source": [
    "# Making Prediction - The Heart of ML\n",
    "data = 'In classification, the algorithms used is logistic regression, decision tree and naive bayes'\n",
    "prediction = model.predict(count_vectorizer.transform([data])[0])\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web development\n"
     ]
    }
   ],
   "source": [
    "data = 'Before creating HTML page and doing your Javascript code on the front end make sure you set up your database. I highly recommend you to use MySQl'\n",
    "prediction = model.predict(count_vectorizer.transform([data])[0])\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python OpenCV\n"
     ]
    }
   ],
   "source": [
    "data = 'During the face detection and recognition there must be feature extraction of person to be recognized. Most common method used in face recognition in Hear Cascade Classifier'\n",
    "prediction = model.predict(count_vectorizer.transform([data])[0])\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dumping and loading the model and vectorizer in disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the model\n",
    "vec_file = 'vectorizer.pickle'\n",
    "pickle.dump(count_vectorizer, open(vec_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "mod_file = 'classification.model'\n",
    "pickle.dump(model, open(mod_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Vectorizer from Disk\n",
    "loaded_vectorizer = pickle.load(open('vectorizer.pickle', 'rb'))\n",
    "\n",
    "# Loading Model from Disk\n",
    "loaded_model = pickle.load(open('classification.model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making prediction from real PDF Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages are  28\n",
      "PDF Book Must Contain At least 100 Pages In Order To Upload In Rep\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Open PDF file\n",
    "object = PyPDF2.PdfFileReader('opencv_tutorial.pdf')\n",
    "\n",
    "# Get number of pages\n",
    "NumPages = object.getNumPages()\n",
    "print('Number of pages are ',NumPages)\n",
    "\n",
    "Text = ''\n",
    "\n",
    "if(NumPages<100):\n",
    "    print('PDF Book Must Contain At least 100 Pages In Order To Upload In Rep')\n",
    "else:\n",
    "    print('This PDF Qualifies, Waiting To Be Uploaded')\n",
    "    # Extracting Text of 20 First pages\n",
    "    for i in range(0,20):\n",
    "        PageObj = object.getPage(i)\n",
    "        Text += PageObj.extractText()\n",
    "        \n",
    "#print(Text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence\n"
     ]
    }
   ],
   "source": [
    "# Making prediction using Model and vectorizer loaded from Disk\n",
    "prediction = loaded_model.predict(loaded_vectorizer.transform([Text])[0])\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You're machine learning engineer already....... What next next woooooah\n",
    "\n",
    "# get prepared to deploy our model on Django, Python web framework for perfectionist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
